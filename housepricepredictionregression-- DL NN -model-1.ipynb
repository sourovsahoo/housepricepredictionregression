{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cleaned dataset from ML notebook\n",
    "\n",
    "X = pandas.read_csv('houseindependentfeature(x)')\n",
    "Y = pandas.read_csv('housedependentfeature(y)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>0.733315</td>\n",
       "      <td>-1.738121</td>\n",
       "      <td>-1.288571</td>\n",
       "      <td>0.328355</td>\n",
       "      <td>-0.289300</td>\n",
       "      <td>-1.409504</td>\n",
       "      <td>0.545992</td>\n",
       "      <td>0.350813</td>\n",
       "      <td>1.582540</td>\n",
       "      <td>0.112235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331780</td>\n",
       "      <td>-0.623809</td>\n",
       "      <td>-0.148167</td>\n",
       "      <td>-0.100425</td>\n",
       "      <td>0.450739</td>\n",
       "      <td>-0.106682</td>\n",
       "      <td>-0.481805</td>\n",
       "      <td>-0.167332</td>\n",
       "      <td>-0.324589</td>\n",
       "      <td>-0.590076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>0.171142</td>\n",
       "      <td>1.058592</td>\n",
       "      <td>-1.074875</td>\n",
       "      <td>-1.140992</td>\n",
       "      <td>0.783542</td>\n",
       "      <td>0.787835</td>\n",
       "      <td>-1.466897</td>\n",
       "      <td>-0.579147</td>\n",
       "      <td>0.090923</td>\n",
       "      <td>1.859657</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.114019</td>\n",
       "      <td>0.167277</td>\n",
       "      <td>1.628146</td>\n",
       "      <td>-1.215375</td>\n",
       "      <td>2.334370</td>\n",
       "      <td>1.723775</td>\n",
       "      <td>2.892024</td>\n",
       "      <td>5.525734</td>\n",
       "      <td>-3.868929</td>\n",
       "      <td>-7.503845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>-1.680940</td>\n",
       "      <td>-0.258180</td>\n",
       "      <td>0.303110</td>\n",
       "      <td>-0.390770</td>\n",
       "      <td>-0.032945</td>\n",
       "      <td>0.334321</td>\n",
       "      <td>-0.591152</td>\n",
       "      <td>-0.483299</td>\n",
       "      <td>0.106842</td>\n",
       "      <td>-1.889094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.634613</td>\n",
       "      <td>-1.464963</td>\n",
       "      <td>0.792218</td>\n",
       "      <td>1.812654</td>\n",
       "      <td>-1.477052</td>\n",
       "      <td>1.139525</td>\n",
       "      <td>-0.747134</td>\n",
       "      <td>0.826388</td>\n",
       "      <td>0.453397</td>\n",
       "      <td>-0.205676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>-0.397531</td>\n",
       "      <td>1.321134</td>\n",
       "      <td>1.882836</td>\n",
       "      <td>0.052593</td>\n",
       "      <td>-0.996835</td>\n",
       "      <td>-1.764419</td>\n",
       "      <td>-0.434382</td>\n",
       "      <td>-0.344336</td>\n",
       "      <td>1.282965</td>\n",
       "      <td>-0.969296</td>\n",
       "      <td>...</td>\n",
       "      <td>1.144884</td>\n",
       "      <td>-0.539174</td>\n",
       "      <td>-0.327358</td>\n",
       "      <td>0.580151</td>\n",
       "      <td>-0.140406</td>\n",
       "      <td>0.075984</td>\n",
       "      <td>-0.223638</td>\n",
       "      <td>-0.366087</td>\n",
       "      <td>0.323312</td>\n",
       "      <td>-0.003670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>-0.380443</td>\n",
       "      <td>0.151356</td>\n",
       "      <td>0.029064</td>\n",
       "      <td>-1.517830</td>\n",
       "      <td>0.495264</td>\n",
       "      <td>-1.394779</td>\n",
       "      <td>-0.201222</td>\n",
       "      <td>-0.193453</td>\n",
       "      <td>0.015431</td>\n",
       "      <td>0.845715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272943</td>\n",
       "      <td>-1.326986</td>\n",
       "      <td>-0.269487</td>\n",
       "      <td>-0.477935</td>\n",
       "      <td>0.611329</td>\n",
       "      <td>-0.610763</td>\n",
       "      <td>-1.096396</td>\n",
       "      <td>0.070089</td>\n",
       "      <td>-0.358060</td>\n",
       "      <td>0.430118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>-0.935842</td>\n",
       "      <td>1.060208</td>\n",
       "      <td>0.189800</td>\n",
       "      <td>0.196797</td>\n",
       "      <td>-0.762822</td>\n",
       "      <td>0.078529</td>\n",
       "      <td>0.053367</td>\n",
       "      <td>0.334417</td>\n",
       "      <td>-2.076686</td>\n",
       "      <td>1.360641</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.515580</td>\n",
       "      <td>-1.402849</td>\n",
       "      <td>1.002390</td>\n",
       "      <td>0.724149</td>\n",
       "      <td>2.000881</td>\n",
       "      <td>0.110515</td>\n",
       "      <td>-1.014898</td>\n",
       "      <td>-1.332115</td>\n",
       "      <td>-0.583252</td>\n",
       "      <td>-0.803204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>-0.558280</td>\n",
       "      <td>-0.069805</td>\n",
       "      <td>-0.174619</td>\n",
       "      <td>-0.733331</td>\n",
       "      <td>0.331690</td>\n",
       "      <td>-0.182541</td>\n",
       "      <td>0.397045</td>\n",
       "      <td>-1.350728</td>\n",
       "      <td>-0.420182</td>\n",
       "      <td>-0.185568</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.360187</td>\n",
       "      <td>2.251332</td>\n",
       "      <td>-0.498293</td>\n",
       "      <td>-0.405133</td>\n",
       "      <td>3.034763</td>\n",
       "      <td>3.131808</td>\n",
       "      <td>1.887797</td>\n",
       "      <td>-2.557489</td>\n",
       "      <td>1.987330</td>\n",
       "      <td>-0.574755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>0.453591</td>\n",
       "      <td>2.545169</td>\n",
       "      <td>-0.336960</td>\n",
       "      <td>0.831364</td>\n",
       "      <td>0.603042</td>\n",
       "      <td>-0.269086</td>\n",
       "      <td>0.940367</td>\n",
       "      <td>-0.084283</td>\n",
       "      <td>0.800700</td>\n",
       "      <td>-0.464561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.460056</td>\n",
       "      <td>0.924993</td>\n",
       "      <td>1.233828</td>\n",
       "      <td>0.507943</td>\n",
       "      <td>-1.420205</td>\n",
       "      <td>-1.149577</td>\n",
       "      <td>0.859540</td>\n",
       "      <td>0.375909</td>\n",
       "      <td>0.173379</td>\n",
       "      <td>-0.841055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>-0.461433</td>\n",
       "      <td>-0.110423</td>\n",
       "      <td>-0.815094</td>\n",
       "      <td>-0.816007</td>\n",
       "      <td>-1.097266</td>\n",
       "      <td>0.403030</td>\n",
       "      <td>-1.506469</td>\n",
       "      <td>-0.915684</td>\n",
       "      <td>0.454093</td>\n",
       "      <td>0.142877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121514</td>\n",
       "      <td>-0.378047</td>\n",
       "      <td>-0.291084</td>\n",
       "      <td>0.281982</td>\n",
       "      <td>0.884172</td>\n",
       "      <td>-0.861789</td>\n",
       "      <td>0.120837</td>\n",
       "      <td>0.399189</td>\n",
       "      <td>-0.311039</td>\n",
       "      <td>0.330971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>-0.418476</td>\n",
       "      <td>-0.422867</td>\n",
       "      <td>-0.614647</td>\n",
       "      <td>-0.878834</td>\n",
       "      <td>-1.286271</td>\n",
       "      <td>0.327244</td>\n",
       "      <td>-1.313352</td>\n",
       "      <td>-0.846136</td>\n",
       "      <td>0.685449</td>\n",
       "      <td>1.369361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.298386</td>\n",
       "      <td>2.276640</td>\n",
       "      <td>-0.874803</td>\n",
       "      <td>-0.794736</td>\n",
       "      <td>0.565831</td>\n",
       "      <td>0.086812</td>\n",
       "      <td>1.065327</td>\n",
       "      <td>-4.400662</td>\n",
       "      <td>-3.364705</td>\n",
       "      <td>-2.226235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "1023  0.733315 -1.738121 -1.288571  0.328355 -0.289300 -1.409504  0.545992   \n",
       "810   0.171142  1.058592 -1.074875 -1.140992  0.783542  0.787835 -1.466897   \n",
       "1384 -1.680940 -0.258180  0.303110 -0.390770 -0.032945  0.334321 -0.591152   \n",
       "626  -0.397531  1.321134  1.882836  0.052593 -0.996835 -1.764419 -0.434382   \n",
       "813  -0.380443  0.151356  0.029064 -1.517830  0.495264 -1.394779 -0.201222   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "462  -0.935842  1.060208  0.189800  0.196797 -0.762822  0.078529  0.053367   \n",
       "129  -0.558280 -0.069805 -0.174619 -0.733331  0.331690 -0.182541  0.397045   \n",
       "845   0.453591  2.545169 -0.336960  0.831364  0.603042 -0.269086  0.940367   \n",
       "331  -0.461433 -0.110423 -0.815094 -0.816007 -1.097266  0.403030 -1.506469   \n",
       "323  -0.418476 -0.422867 -0.614647 -0.878834 -1.286271  0.327244 -1.313352   \n",
       "\n",
       "             7         8         9  ...        60        61        62  \\\n",
       "1023  0.350813  1.582540  0.112235  ...  0.331780 -0.623809 -0.148167   \n",
       "810  -0.579147  0.090923  1.859657  ... -1.114019  0.167277  1.628146   \n",
       "1384 -0.483299  0.106842 -1.889094  ...  0.634613 -1.464963  0.792218   \n",
       "626  -0.344336  1.282965 -0.969296  ...  1.144884 -0.539174 -0.327358   \n",
       "813  -0.193453  0.015431  0.845715  ...  0.272943 -1.326986 -0.269487   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "462   0.334417 -2.076686  1.360641  ... -0.515580 -1.402849  1.002390   \n",
       "129  -1.350728 -0.420182 -0.185568  ... -0.360187  2.251332 -0.498293   \n",
       "845  -0.084283  0.800700 -0.464561  ...  0.460056  0.924993  1.233828   \n",
       "331  -0.915684  0.454093  0.142877  ...  0.121514 -0.378047 -0.291084   \n",
       "323  -0.846136  0.685449  1.369361  ...  0.298386  2.276640 -0.874803   \n",
       "\n",
       "            63        64        65        66        67        68        69  \n",
       "1023 -0.100425  0.450739 -0.106682 -0.481805 -0.167332 -0.324589 -0.590076  \n",
       "810  -1.215375  2.334370  1.723775  2.892024  5.525734 -3.868929 -7.503845  \n",
       "1384  1.812654 -1.477052  1.139525 -0.747134  0.826388  0.453397 -0.205676  \n",
       "626   0.580151 -0.140406  0.075984 -0.223638 -0.366087  0.323312 -0.003670  \n",
       "813  -0.477935  0.611329 -0.610763 -1.096396  0.070089 -0.358060  0.430118  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "462   0.724149  2.000881  0.110515 -1.014898 -1.332115 -0.583252 -0.803204  \n",
       "129  -0.405133  3.034763  3.131808  1.887797 -2.557489  1.987330 -0.574755  \n",
       "845   0.507943 -1.420205 -1.149577  0.859540  0.375909  0.173379 -0.841055  \n",
       "331   0.281982  0.884172 -0.861789  0.120837  0.399189 -0.311039  0.330971  \n",
       "323  -0.794736  0.565831  0.086812  1.065327 -4.400662 -3.364705 -2.226235  \n",
       "\n",
       "[70 rows x 70 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1095, 70), (365, 70))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1095, 1), (365, 1))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Model structure development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.models.Sequential([\n",
    "                                 #column=70   ,,give column numbers in rows place for input_shape=(number of columns,). \n",
    "    tf.keras.layers.Flatten(input_shape=(70,)),\n",
    "                          #128,no.of neurons in the 2nd layer.\n",
    "    tf.keras.layers.Dense(128,activation='relu'),\n",
    "                    #Dropout()Regularization technique to avoid overfitting .\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x22d534aa3d0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x22d537a62b0>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x22d537a6220>]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 70)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 128)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_15 (Flatten)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 128)               9088      \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "=================================================================\n",
      "Total params: 9,088\n",
      "Trainable params: 9,088\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "                                                  # Weight * x +1 Bias\n",
    "model.summary()#input 28 * 28 = 784 ,100480/128=785(784 + 1 Bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2201306 , 0.        , 0.        , ..., 0.        , 0.9221962 ,\n",
       "        0.2670672 ],\n",
       "       [0.32530898, 0.047813  , 1.1816788 , ..., 0.18694389, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.80018014, 0.        , ..., 0.        , 0.62191594,\n",
       "        0.20271286],\n",
       "       ...,\n",
       "       [0.46654418, 0.30700964, 0.        , ..., 0.46799222, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 1.1705772 , 0.35593474, ..., 0.50273883, 1.2107043 ,\n",
       "        0.2718138 ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.66404927, 0.        ,\n",
       "        0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions=model.predict(x_train[:1095])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1095, 128)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              \n",
    "              loss=['mean_squared_error'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now adam and mse are incorporated in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The model.fit method adjusts the model parameters to maximize the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 136.9728\n",
      "Epoch 2/5\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 135.7511\n",
      "Epoch 3/5\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 134.5360\n",
      "Epoch 4/5\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 133.4500\n",
      "Epoch 5/5\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 132.2816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22d5386e3d0>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation on test set"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The model.evaluate method checks the models performance usually on a Validation or test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 - 0s - loss: 131.9427\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "131.9427490234375"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparision with ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE score=131.9427 < 135.378   as in case of ML model.\n",
    "We can see the RMSE error decreasing in this case of deep learning model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    # create model\n",
    "    model=tf.keras.models.Sequential([\n",
    "                            #column=70   ,,give column numbers in rows place for input_shape=(number of columns,). \n",
    "    tf.keras.layers.Flatten(input_shape=(70,)),\n",
    "                          #128,no.of neurons in the 2nd layer.\n",
    "    tf.keras.layers.Dense(128,activation='relu'),\n",
    "                    #Dropout()Regularization technique to avoid overfitting .\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "])\n",
    "    \n",
    "  # Compile model\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVS= -5.84 MSE= (0.07) \n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "estimator = KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=10)\n",
    "results = cross_val_score(estimator, X, Y, cv=kfold)\n",
    "print(\"CVS= %.2f MSE= (%.2f) \" % (results.mean(), results.std()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
